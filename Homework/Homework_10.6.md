# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

| **PM сбоя системы Github**  |           | 
|-----------------------------|-----------|
| Краткое описание инцидента	| В 22:52 21 октября 2018 в связи с проблемой на сетевых разделах и последущего сбоя на БД, были затронуты некоторые службы GitHub. В результатае возникла несогласованность информации на сервисах и произошла деградация сервиса. |
| Предшествующие события      | 21 октября 2018 г. в 22:52 по UTC была потеря соединения на 1000Гб оптическом канали связи между ХАБом US West Coast и Основным ЦОДом US East Coast data center. |
| Причина инцидента           | Плановая замена сетевого оборудования и последующая потеря сетевого соединения между сетевым узлом и основным ЦОД на Восточном побережье США (на 43 секунды), вызвали перестроение распределенного кластера СУБД, что привело к несогласованности кластеров. |
| Воздействие                 | Инцидент привёл к деградации работы сервиса и ухудшению качества обслуживания, таких как отображение устаревших данных в пользовательском веб-интерфейсе, доступность данных и других проблем с работой сервиса.  |
| Обнаружение                 | Инцидент был замечен инженерами из группы мониторинга.  |
| Реакция                     | Инцидент бы устранён в течении 24 часов 11 минут. В период инцидента наблюдалась деградация сервиса. |
| Восстановление              | Было выполнено восстановление баз данных из резервных копий и синхронизация реплик.  |
| Таймлайн                    | 2018 October 21 22:52 UTC: </br> Произошла потеря потери связи между сетевым узлом на Восточном побережье США и основным ЦОД на Восточном побережье США (восстановление связи заняло 43 сек.), но данное отключение вызвало дальнейшую цепочку событий. После перестроения кластера серверы БД в ЦОД Восточного побережья США содержали часть записей, которые не были реплицированы на объект Западного побережья США.|
|                             | 2018 October 21 22:54 UTC: </br> Внутренние системы мониторинга начали генерировать алерты, указывающие на многочисленные сбои. К 23:02 UTC инженеры из группы мониторинга, обнаружили несоответствие статуса кластера ожидаемому. Запрос API Orchestrator отобразил топологию репликации базы данных, которая включала только серверы из ЦОД на Западном побережье США.|
|                             | 2018 October 21 23:07 UTC: </br> К этому моменту отвечающая команда решила вручную заблокировать внутренний инструментарий развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений. В 23:09 UTC группа реагирования присвоила сайту желтый статус. Это действие автоматически превратило ситуацию в активный инцидент и отправило предупреждение координатору инцидентов. В 23:11 UTC координатор инцидента присоединился и через две минуты принял решение изменить статус на красный.|
|                             | 2018 October 21 23:13 UTC: </br> В то время стало понятно, что проблема затронула несколько кластеров баз данных. Были вызваны дополнительные инженеры из команды разработчиков баз данных GitHub. К этому моменту кластер баз данных Западного побережья принимал записи с уровня приложений в течение почти 40 минут. Кроме того, в кластере Восточного побережья существовало несколько секунд записей, которые не были реплицированы на Западное побережье и препятствовали репликации новых записей обратно на Восточное побережье. Стремясь сохранить пользовательские данные, было принято решение в пользу целостности данных, в ущерб их доступности.|
|                             | 2018 October 21 23:19 UTC: </br> Были остановлены некоторые процессы, проведена принудительная деградация системы, с целью повышения скорости восстановления.|
|                             | 2018 October 22 00:05 UTC: </br> Разработка плана по устранению несоответствий данных и внедрению наших процедур аварийного переключения для MySQL. План состоял в том, чтобы восстановить из резервных копий, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди.|
|                             | 2018 October 22 00:41 UTC: </br> Запущен процесс резервного копирования данных для всех затронутых кластеров. Одновременно несколько групп инженеров искали способы ускорить передачу и время восстановления без дальнейшего ухудшения удобства использования сайта или риска повреждения данных.|
|                             | 2018 October 22 06:51 UTC: </br> Несколько кластеров завершили восстановление из резервных копий в ЦОД на восточном побережье США и начали репликацию новых данных с западного побережья. Ожидаемое время восстановления составляло два часа.|
|                             | 2018 October 22 07:46 UTC: </br> GitHub опубликовал сообщение в блоге с расширенной информацией для пользователей, о ходе инцидента и извинениями за задержку.|
|                             | 2018 October 22 11:12 UTC: </br> Восстановлены сервера в US East Coast, что привело к уменьшению деградации на сайте, продолжается реплицирование. Из-за возросшей нагрузки на наши кластеры баз данных, когда пользователи начали свой рабочий день в Европе и США, процесс восстановления занял больше времени, чем первоначально предполагалось.|
|                             | 2018 October 22 13:15 UTC: </br> По приближению к пиковой нагрузке трафика на GitHub.com. Начали предоставлять дополнительные реплики чтения MySQL в общедоступном облаке восточного побережья США. Как только они стали доступны, стало проще распределять объем запросов на чтение по большему количеству серверов. Сокращение совокупного использования реплик чтения позволило репликации наверстать упущенное.|
|                             | 2018 October 22 16:24 UTC: </br> Как только реплики были синхронизированы, было выполнено аварийное переключение на исходную топологию, что решило проблемы с задержкой/доступностью.|
|                             | 2018 October 22 16:45 UTC: </br> После восстановления возникла необходимость балансировки нагрузки да восстановления 100% услуг клиентам. Для восстановления уже имеющихся данных пользователей включили обработку, так же подняли TTL до полного завершения и возвращения к штатной работе.|
|                             | 2018 October 22 23:03 UTC: </br> Все ожидающие вебхуки и страницы были обработаны, и была подтверждена целостность и правильная работа всех систем. Статус сайта был обновлен до зеленого.|
| Последующие действия        | Настройка конфигурациии Оркестратора, для снижения рисков поведения вызвашего инцидент. </br> </br> Ускорение перехода к новому механизму отчётов о состоянии сервиса, который предоставит нам большие возможности для обсуждения активных инцидентов. </br> </br> За несколько недель до этого инцидента, была начата общекорпоративная инженерная инициатива по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в режиме active/active/active. </br> Целью этого проекта является поддержка резервирования N+1 на уровне объекта. </br> Цель этой работы — допустить полный отказ одного центра обработки данных без воздействия на пользователя. </br> </br> Этот инцидент изменил отношение к надежности сайта. </br> Выяснили, что более строгий операционный контроль или улучшение времени отклика являются недостаточными гарантиями надежности сайта. </br> Будет создана системная практика проверки сценариев сбоев, прежде чем они смогут повлиять на вас. |


---
